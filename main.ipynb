{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "TJX_lUPqmfhJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c00c59b6-8d18-427e-b7ec-b723005e83c2"
      },
      "source": [
        "# Colab settings\n",
        "!wget --header=\"Host: archive.ics.uci.edu\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7\" --header=\"Referer: https://archive.ics.uci.edu/ml/machine-learning-databases/00363/\" \"https://archive.ics.uci.edu/ml/machine-learning-databases/00363/Dataset.zip\" -O \"Dataset.zip\" -c\n",
        "!unzip Dataset.zip\n",
        "!git clone https://github.com/janchk/ML_HOMEWORK1\n",
        "from ML_HOMEWORK1.src.models import LinearRegressionWithGd\n",
        "from ML_HOMEWORK1.src.common import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-13 17:30:43--  https://archive.ics.uci.edu/ml/machine-learning-databases/00363/Dataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19055526 (18M) [application/x-httpd-php]\n",
            "Saving to: ‘Dataset.zip’\n",
            "\n",
            "Dataset.zip         100%[===================>]  18.17M  19.8MB/s    in 0.9s    \n",
            "\n",
            "2020-02-13 17:30:44 (19.8 MB/s) - ‘Dataset.zip’ saved [19055526/19055526]\n",
            "\n",
            "Archive:  Dataset.zip\n",
            "   creating: Dataset/\n",
            "  inflating: Dataset/.DS_Store       \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/Dataset/\n",
            "  inflating: __MACOSX/Dataset/._.DS_Store  \n",
            "  inflating: Dataset/Catagory_File - Feature 4.pdf  \n",
            "  inflating: __MACOSX/Dataset/._Catagory_File - Feature 4.pdf  \n",
            "   creating: Dataset/Testing/\n",
            "  inflating: Dataset/Testing/.DS_Store  \n",
            "   creating: __MACOSX/Dataset/Testing/\n",
            "  inflating: __MACOSX/Dataset/Testing/._.DS_Store  \n",
            "  inflating: Dataset/Testing/Features_TestSet.csv  \n",
            "  inflating: __MACOSX/Dataset/Testing/._Features_TestSet.csv  \n",
            "   creating: Dataset/Testing/TestSet/\n",
            "  inflating: Dataset/Testing/TestSet/Test_Case_1.arff  \n",
            "   creating: __MACOSX/Dataset/Testing/TestSet/\n",
            "  inflating: __MACOSX/Dataset/Testing/TestSet/._Test_Case_1.arff  \n",
            "  inflating: Dataset/Testing/TestSet/Test_Case_1.csv  \n",
            "  inflating: __MACOSX/Dataset/Testing/TestSet/._Test_Case_1.csv  \n",
            "  inflating: Dataset/Testing/TestSet/Test_Case_10.arff  \n",
            "  inflating: __MACOSX/Dataset/Testing/TestSet/._Test_Case_10.arff  \n",
            "  inflating: Dataset/Testing/TestSet/Test_Case_10.csv  \n",
            "  inflating: __MACOSX/Dataset/Testing/TestSet/._Test_Case_10.csv  \n",
            "  inflating: Dataset/Testing/TestSet/Test_Case_2.arff  \n",
            "  inflating: __MACOSX/Dataset/Testing/TestSet/._Test_Case_2.arff  \n",
            "  inflating: Dataset/Testing/TestSet/Test_Case_2.csv  \n",
            "  inflating: __MACOSX/Dataset/Testing/TestSet/._Test_Case_2.csv  \n",
            "  inflating: Dataset/Testing/TestSet/Test_Case_3.arff  \n",
            "  inflating: __MACOSX/Dataset/Testing/TestSet/._Test_Case_3.arff  \n",
            "  inflating: Dataset/Testing/TestSet/Test_Case_3.csv  \n",
            "  inflating: __MACOSX/Dataset/Testing/TestSet/._Test_Case_3.csv  \n",
            "  inflating: Dataset/Testing/TestSet/Test_Case_4.arff  \n",
            "  inflating: __MACOSX/Dataset/Testing/TestSet/._Test_Case_4.arff  \n",
            "  inflating: Dataset/Testing/TestSet/Test_Case_4.csv  \n",
            "  inflating: __MACOSX/Dataset/Testing/TestSet/._Test_Case_4.csv  \n",
            "  inflating: Dataset/Testing/TestSet/Test_Case_5.arff  \n",
            "  inflating: __MACOSX/Dataset/Testing/TestSet/._Test_Case_5.arff  \n",
            "  inflating: Dataset/Testing/TestSet/Test_Case_5.csv  \n",
            "  inflating: __MACOSX/Dataset/Testing/TestSet/._Test_Case_5.csv  \n",
            "  inflating: Dataset/Testing/TestSet/Test_Case_6.arff  \n",
            "  inflating: __MACOSX/Dataset/Testing/TestSet/._Test_Case_6.arff  \n",
            "  inflating: Dataset/Testing/TestSet/Test_Case_6.csv  \n",
            "  inflating: __MACOSX/Dataset/Testing/TestSet/._Test_Case_6.csv  \n",
            "  inflating: Dataset/Testing/TestSet/Test_Case_7.arff  \n",
            "  inflating: __MACOSX/Dataset/Testing/TestSet/._Test_Case_7.arff  \n",
            "  inflating: Dataset/Testing/TestSet/Test_Case_7.csv  \n",
            "  inflating: __MACOSX/Dataset/Testing/TestSet/._Test_Case_7.csv  \n",
            "  inflating: Dataset/Testing/TestSet/Test_Case_8.arff  \n",
            "  inflating: __MACOSX/Dataset/Testing/TestSet/._Test_Case_8.arff  \n",
            "  inflating: Dataset/Testing/TestSet/Test_Case_8.csv  \n",
            "  inflating: __MACOSX/Dataset/Testing/TestSet/._Test_Case_8.csv  \n",
            "  inflating: Dataset/Testing/TestSet/Test_Case_9.arff  \n",
            "  inflating: __MACOSX/Dataset/Testing/TestSet/._Test_Case_9.arff  \n",
            "  inflating: Dataset/Testing/TestSet/Test_Case_9.csv  \n",
            "  inflating: __MACOSX/Dataset/Testing/TestSet/._Test_Case_9.csv  \n",
            "  inflating: __MACOSX/Dataset/Testing/._TestSet  \n",
            "   creating: Dataset/Training/\n",
            "  inflating: Dataset/Training/Features_Variant_1.arff  \n",
            "   creating: __MACOSX/Dataset/Training/\n",
            "  inflating: __MACOSX/Dataset/Training/._Features_Variant_1.arff  \n",
            "  inflating: Dataset/Training/Features_Variant_1.csv  \n",
            "  inflating: __MACOSX/Dataset/Training/._Features_Variant_1.csv  \n",
            "  inflating: Dataset/Training/Features_Variant_2.arff  \n",
            "  inflating: __MACOSX/Dataset/Training/._Features_Variant_2.arff  \n",
            "  inflating: Dataset/Training/Features_Variant_2.csv  \n",
            "  inflating: __MACOSX/Dataset/Training/._Features_Variant_2.csv  \n",
            "  inflating: Dataset/Training/Features_Variant_3.arff  \n",
            "  inflating: __MACOSX/Dataset/Training/._Features_Variant_3.arff  \n",
            "  inflating: Dataset/Training/Features_Variant_3.csv  \n",
            "  inflating: __MACOSX/Dataset/Training/._Features_Variant_3.csv  \n",
            "  inflating: Dataset/Training/Features_Variant_4.arff  \n",
            "  inflating: __MACOSX/Dataset/Training/._Features_Variant_4.arff  \n",
            "  inflating: Dataset/Training/Features_Variant_4.csv  \n",
            "  inflating: __MACOSX/Dataset/Training/._Features_Variant_4.csv  \n",
            "  inflating: Dataset/Training/Features_Variant_5.arff  \n",
            "  inflating: __MACOSX/Dataset/Training/._Features_Variant_5.arff  \n",
            "  inflating: Dataset/Training/Features_Variant_5.csv  \n",
            "  inflating: __MACOSX/Dataset/Training/._Features_Variant_5.csv  \n",
            "Cloning into 'ML_HOMEWORK1'...\n",
            "remote: Enumerating objects: 143, done.\u001b[K\n",
            "remote: Counting objects: 100% (143/143), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 143 (delta 72), reused 137 (delta 66), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (143/143), 28.41 KiB | 3.55 MiB/s, done.\n",
            "Resolving deltas: 100% (72/72), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "zau4JDmwmfhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import part \n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "# from src.models import LinearRegressionWithGd\n",
        "# from src.common import *\n",
        "import pandas as pd\n",
        "path = \"Dataset/Training/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "n86ECMHHmfhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# configuration\n",
        "num_folds = 5\n",
        "epochs = 1000\n",
        "learning_rate = 1e-3\n",
        "\n",
        "lrg = LinearRegressionWithGd()\n",
        "lrg.learning_rate = learning_rate\n",
        "\n",
        "df_1, df_2 = folding(path)\n",
        "np.random.shuffle(df_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "T61-vfjAmfhl",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "0m4ThGeMmfhn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "e7992c40-806b-4375-dc42-61107df3ba4b"
      },
      "source": [
        "features = []\n",
        "bias = []\n",
        "stats = []\n",
        "losses = [] #loss per fold\n",
        "for i in range(num_folds):\n",
        "    train, test = cv_loo(df_1, num_folds, i)\n",
        "\n",
        "    X_train = normalized(train.T[0:53].T)\n",
        "    X_test = normalized(test.T[0:53].T)\n",
        "\n",
        "    Y_train = train.T[53].T\n",
        "    Y_train = np.expand_dims(Y_train, axis=-1)\n",
        "\n",
        "    Y_test = test.T[53].T\n",
        "    Y_test = np.expand_dims(Y_test, axis=-1)\n",
        "\n",
        "    loss = lrg.train(epochs, X_train, Y_train)\n",
        "    stat = lrg.validate(X_test, Y_test)\n",
        "    losses.append(loss)\n",
        "    stats.append(stat)\n",
        "    features.append(lrg.betas)\n",
        "    bias.append(*lrg.bias)\n",
        "    \n",
        "\n",
        "mean_stats = np.sum(stats, axis=0) / num_folds\n",
        "print(\"mse_val is {}, r2_val is {}, rmse is {}, r2/rmse {}\".format(\n",
        "    mean_stats[0], mean_stats[1], mean_stats[2], mean_stats[3]))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 959.9274: 100%|██████████| 1000/1000 [00:41<00:00, 24.29it/s]\n",
            "Loss: 824.5289:   0%|          | 2/1000 [00:00<00:50, 19.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val loss is 563.167709900831, R2 is 0.3927794934057012, RMSE is 23.731154837066633, R2/RMSE is 0.016551217001551197\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 821.7298: 100%|██████████| 1000/1000 [00:48<00:00, 20.31it/s]\n",
            "Loss: 900.8882:   0%|          | 2/1000 [00:00<00:50, 19.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val loss is 1118.6737348756358, R2 is 0.29374966848665085, RMSE is 33.446580316612874, R2/RMSE is 0.008782651789987205\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 896.7526: 100%|██████████| 1000/1000 [00:49<00:00, 20.38it/s]\n",
            "Loss: 835.8405:   0%|          | 3/1000 [00:00<00:48, 20.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val loss is 815.4430268191686, R2 is 0.3091650683731676, RMSE is 28.555963069369042, R2/RMSE is 0.010826637771667308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 831.2071: 100%|██████████| 1000/1000 [00:47<00:00, 21.08it/s]\n",
            "Loss: 884.0796:   0%|          | 0/1000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val loss is 1083.3847656253267, R2 is 0.295700999591313, RMSE is 32.914810733548606, R2/RMSE is 0.008983828039755918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 878.4064: 100%|██████████| 1000/1000 [00:49<00:00, 20.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val loss is 881.4466831550576, R2 is 0.3045791984233345, RMSE is 29.689167774713013, R2/RMSE is 0.010258933518599736\n",
            "mse_val is 892.423184075204, r2_val is 0.3191948856560335, rmse is 29.667535346262035, r2/rmse 0.011080653624312273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "wN5EebUvmfhw",
        "colab_type": "text"
      },
      "source": [
        "### Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "DB-5tvosmfhy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "c6ece8ed-8585-4113-e716-9f7a0d6ee624"
      },
      "source": [
        "columns = [\"bias\"] + [f\"f{f+1}\" for f in range(len(features[0]))]\n",
        "index = [f\"Fold {i+1}\" for i, _ in enumerate(features)] + [\"mean\"] + [\"std\"]\n",
        "\n",
        "bias_np = np.expand_dims(np.squeeze(bias), 1)\n",
        "features_np = np.squeeze(features, axis=2)\n",
        "features_np = np.hstack((bias, features_np))\n",
        "features_mean = np.mean(features_np, axis=0)\n",
        "features_std = np.std(features_np, axis=0)\n",
        "df = pd.DataFrame(np.vstack((features_np, features_mean, features_std )),\n",
        "                  columns=columns,\n",
        "                  index=index)\n",
        "\n",
        "display.display(df)    "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bias</th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>f9</th>\n",
              "      <th>f10</th>\n",
              "      <th>f11</th>\n",
              "      <th>f12</th>\n",
              "      <th>f13</th>\n",
              "      <th>f14</th>\n",
              "      <th>f15</th>\n",
              "      <th>f16</th>\n",
              "      <th>f17</th>\n",
              "      <th>f18</th>\n",
              "      <th>f19</th>\n",
              "      <th>f20</th>\n",
              "      <th>f21</th>\n",
              "      <th>f22</th>\n",
              "      <th>f23</th>\n",
              "      <th>f24</th>\n",
              "      <th>f25</th>\n",
              "      <th>f26</th>\n",
              "      <th>f27</th>\n",
              "      <th>f28</th>\n",
              "      <th>f29</th>\n",
              "      <th>f30</th>\n",
              "      <th>f31</th>\n",
              "      <th>f32</th>\n",
              "      <th>f33</th>\n",
              "      <th>f34</th>\n",
              "      <th>f35</th>\n",
              "      <th>f36</th>\n",
              "      <th>f37</th>\n",
              "      <th>f38</th>\n",
              "      <th>f39</th>\n",
              "      <th>f40</th>\n",
              "      <th>f41</th>\n",
              "      <th>f42</th>\n",
              "      <th>f43</th>\n",
              "      <th>f44</th>\n",
              "      <th>f45</th>\n",
              "      <th>f46</th>\n",
              "      <th>f47</th>\n",
              "      <th>f48</th>\n",
              "      <th>f49</th>\n",
              "      <th>f50</th>\n",
              "      <th>f51</th>\n",
              "      <th>f52</th>\n",
              "      <th>f53</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Fold 1</th>\n",
              "      <td>7.294475</td>\n",
              "      <td>0.395839</td>\n",
              "      <td>-0.096299</td>\n",
              "      <td>-1.460429</td>\n",
              "      <td>0.055669</td>\n",
              "      <td>-0.971484</td>\n",
              "      <td>0.834369</td>\n",
              "      <td>2.077066</td>\n",
              "      <td>1.556115</td>\n",
              "      <td>3.397266</td>\n",
              "      <td>1.983012</td>\n",
              "      <td>-1.119421</td>\n",
              "      <td>-0.411491</td>\n",
              "      <td>6.288889</td>\n",
              "      <td>-0.890636</td>\n",
              "      <td>-0.447877</td>\n",
              "      <td>0.792554</td>\n",
              "      <td>-0.481599</td>\n",
              "      <td>-0.412024</td>\n",
              "      <td>0.133312</td>\n",
              "      <td>-1.315610</td>\n",
              "      <td>0.021517</td>\n",
              "      <td>-0.426100</td>\n",
              "      <td>1.134811</td>\n",
              "      <td>0.288421</td>\n",
              "      <td>1.607342</td>\n",
              "      <td>-0.600967</td>\n",
              "      <td>0.907121</td>\n",
              "      <td>-1.722465</td>\n",
              "      <td>-0.859328</td>\n",
              "      <td>-0.862891</td>\n",
              "      <td>10.025607</td>\n",
              "      <td>3.301377</td>\n",
              "      <td>-1.735529</td>\n",
              "      <td>6.817985</td>\n",
              "      <td>-4.077646</td>\n",
              "      <td>0.041734</td>\n",
              "      <td>2.374424</td>\n",
              "      <td>0.909436</td>\n",
              "      <td>0.923781</td>\n",
              "      <td>0.562549</td>\n",
              "      <td>0.647912</td>\n",
              "      <td>0.937701</td>\n",
              "      <td>0.988534</td>\n",
              "      <td>0.625553</td>\n",
              "      <td>0.696607</td>\n",
              "      <td>0.536298</td>\n",
              "      <td>0.924596</td>\n",
              "      <td>1.183344</td>\n",
              "      <td>1.037183</td>\n",
              "      <td>1.093827</td>\n",
              "      <td>0.602390</td>\n",
              "      <td>0.898531</td>\n",
              "      <td>0.950712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fold 2</th>\n",
              "      <td>7.162263</td>\n",
              "      <td>0.237424</td>\n",
              "      <td>-0.082128</td>\n",
              "      <td>-1.353467</td>\n",
              "      <td>-0.004047</td>\n",
              "      <td>-0.300492</td>\n",
              "      <td>0.910094</td>\n",
              "      <td>3.079327</td>\n",
              "      <td>1.089313</td>\n",
              "      <td>4.571588</td>\n",
              "      <td>1.428987</td>\n",
              "      <td>-0.725533</td>\n",
              "      <td>-1.078221</td>\n",
              "      <td>5.736223</td>\n",
              "      <td>-0.343539</td>\n",
              "      <td>-0.388720</td>\n",
              "      <td>0.740045</td>\n",
              "      <td>-0.858236</td>\n",
              "      <td>-0.170227</td>\n",
              "      <td>-0.575124</td>\n",
              "      <td>-0.700417</td>\n",
              "      <td>-0.854088</td>\n",
              "      <td>-0.725358</td>\n",
              "      <td>0.166017</td>\n",
              "      <td>-0.183001</td>\n",
              "      <td>1.645220</td>\n",
              "      <td>-0.321681</td>\n",
              "      <td>0.071049</td>\n",
              "      <td>-1.184848</td>\n",
              "      <td>-0.400543</td>\n",
              "      <td>-0.774815</td>\n",
              "      <td>10.467188</td>\n",
              "      <td>3.759741</td>\n",
              "      <td>-2.132777</td>\n",
              "      <td>6.828751</td>\n",
              "      <td>-3.882622</td>\n",
              "      <td>-0.012632</td>\n",
              "      <td>2.540224</td>\n",
              "      <td>0.909436</td>\n",
              "      <td>0.894902</td>\n",
              "      <td>0.643654</td>\n",
              "      <td>0.571186</td>\n",
              "      <td>0.710026</td>\n",
              "      <td>0.952778</td>\n",
              "      <td>0.716888</td>\n",
              "      <td>0.694228</td>\n",
              "      <td>0.721176</td>\n",
              "      <td>0.837320</td>\n",
              "      <td>1.083422</td>\n",
              "      <td>0.875582</td>\n",
              "      <td>1.210937</td>\n",
              "      <td>0.824143</td>\n",
              "      <td>0.873896</td>\n",
              "      <td>0.970839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fold 3</th>\n",
              "      <td>7.201744</td>\n",
              "      <td>0.255087</td>\n",
              "      <td>-0.032151</td>\n",
              "      <td>-1.129055</td>\n",
              "      <td>0.097649</td>\n",
              "      <td>-0.973995</td>\n",
              "      <td>1.556766</td>\n",
              "      <td>4.263272</td>\n",
              "      <td>2.074270</td>\n",
              "      <td>5.948839</td>\n",
              "      <td>1.982965</td>\n",
              "      <td>-0.652972</td>\n",
              "      <td>-1.827341</td>\n",
              "      <td>7.583483</td>\n",
              "      <td>-0.930723</td>\n",
              "      <td>-0.476074</td>\n",
              "      <td>1.164423</td>\n",
              "      <td>-2.025478</td>\n",
              "      <td>-0.359240</td>\n",
              "      <td>-1.210601</td>\n",
              "      <td>-1.413115</td>\n",
              "      <td>-1.781033</td>\n",
              "      <td>-1.048064</td>\n",
              "      <td>1.065007</td>\n",
              "      <td>-0.902392</td>\n",
              "      <td>1.505582</td>\n",
              "      <td>-0.432042</td>\n",
              "      <td>0.645395</td>\n",
              "      <td>-2.029255</td>\n",
              "      <td>-0.812754</td>\n",
              "      <td>-0.822418</td>\n",
              "      <td>10.425203</td>\n",
              "      <td>3.676976</td>\n",
              "      <td>-2.475050</td>\n",
              "      <td>6.859202</td>\n",
              "      <td>-3.846473</td>\n",
              "      <td>-0.031882</td>\n",
              "      <td>2.178871</td>\n",
              "      <td>0.909436</td>\n",
              "      <td>0.781396</td>\n",
              "      <td>0.538932</td>\n",
              "      <td>0.535513</td>\n",
              "      <td>0.974724</td>\n",
              "      <td>0.951021</td>\n",
              "      <td>0.653899</td>\n",
              "      <td>0.717623</td>\n",
              "      <td>0.624753</td>\n",
              "      <td>0.963596</td>\n",
              "      <td>1.039735</td>\n",
              "      <td>1.158655</td>\n",
              "      <td>1.053839</td>\n",
              "      <td>0.645763</td>\n",
              "      <td>0.849183</td>\n",
              "      <td>0.977069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fold 4</th>\n",
              "      <td>7.118850</td>\n",
              "      <td>-0.118362</td>\n",
              "      <td>-0.371504</td>\n",
              "      <td>-0.845635</td>\n",
              "      <td>-0.043549</td>\n",
              "      <td>-0.835140</td>\n",
              "      <td>1.695044</td>\n",
              "      <td>4.962766</td>\n",
              "      <td>1.452973</td>\n",
              "      <td>7.150771</td>\n",
              "      <td>2.231402</td>\n",
              "      <td>-0.831439</td>\n",
              "      <td>-1.865417</td>\n",
              "      <td>8.347602</td>\n",
              "      <td>-0.554145</td>\n",
              "      <td>-0.191494</td>\n",
              "      <td>1.551400</td>\n",
              "      <td>-2.692420</td>\n",
              "      <td>-2.421422</td>\n",
              "      <td>-1.138823</td>\n",
              "      <td>-1.550988</td>\n",
              "      <td>-2.603975</td>\n",
              "      <td>-1.595638</td>\n",
              "      <td>0.581491</td>\n",
              "      <td>-1.247336</td>\n",
              "      <td>1.603906</td>\n",
              "      <td>-0.411382</td>\n",
              "      <td>1.879966</td>\n",
              "      <td>-5.207752</td>\n",
              "      <td>-1.128642</td>\n",
              "      <td>-0.875179</td>\n",
              "      <td>10.633536</td>\n",
              "      <td>4.074087</td>\n",
              "      <td>-2.572915</td>\n",
              "      <td>6.722703</td>\n",
              "      <td>-3.790248</td>\n",
              "      <td>0.018087</td>\n",
              "      <td>2.554140</td>\n",
              "      <td>0.909436</td>\n",
              "      <td>0.930578</td>\n",
              "      <td>0.574611</td>\n",
              "      <td>0.688458</td>\n",
              "      <td>0.901315</td>\n",
              "      <td>0.999955</td>\n",
              "      <td>0.642758</td>\n",
              "      <td>0.644788</td>\n",
              "      <td>0.545748</td>\n",
              "      <td>1.002189</td>\n",
              "      <td>1.141475</td>\n",
              "      <td>1.036694</td>\n",
              "      <td>1.029036</td>\n",
              "      <td>0.645332</td>\n",
              "      <td>0.921416</td>\n",
              "      <td>0.912103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fold 5</th>\n",
              "      <td>7.178907</td>\n",
              "      <td>0.451700</td>\n",
              "      <td>-0.193969</td>\n",
              "      <td>-1.359041</td>\n",
              "      <td>-0.034673</td>\n",
              "      <td>-0.407584</td>\n",
              "      <td>2.182018</td>\n",
              "      <td>5.374624</td>\n",
              "      <td>1.430862</td>\n",
              "      <td>7.660935</td>\n",
              "      <td>2.410786</td>\n",
              "      <td>-0.511798</td>\n",
              "      <td>-2.426799</td>\n",
              "      <td>8.870484</td>\n",
              "      <td>-0.741650</td>\n",
              "      <td>-0.438423</td>\n",
              "      <td>1.486931</td>\n",
              "      <td>-2.411572</td>\n",
              "      <td>-1.634192</td>\n",
              "      <td>-1.156137</td>\n",
              "      <td>-1.204491</td>\n",
              "      <td>-2.630658</td>\n",
              "      <td>-2.230507</td>\n",
              "      <td>0.315005</td>\n",
              "      <td>-1.998505</td>\n",
              "      <td>1.790806</td>\n",
              "      <td>-0.057924</td>\n",
              "      <td>-0.079634</td>\n",
              "      <td>-2.549875</td>\n",
              "      <td>-0.865560</td>\n",
              "      <td>-0.641928</td>\n",
              "      <td>10.932824</td>\n",
              "      <td>4.060351</td>\n",
              "      <td>-2.558109</td>\n",
              "      <td>6.973341</td>\n",
              "      <td>-3.787766</td>\n",
              "      <td>0.006205</td>\n",
              "      <td>2.485699</td>\n",
              "      <td>0.909436</td>\n",
              "      <td>0.981086</td>\n",
              "      <td>0.581097</td>\n",
              "      <td>0.697814</td>\n",
              "      <td>0.863638</td>\n",
              "      <td>1.000216</td>\n",
              "      <td>0.698247</td>\n",
              "      <td>0.644893</td>\n",
              "      <td>0.512153</td>\n",
              "      <td>0.989877</td>\n",
              "      <td>1.206975</td>\n",
              "      <td>1.019986</td>\n",
              "      <td>1.037286</td>\n",
              "      <td>0.634347</td>\n",
              "      <td>0.918059</td>\n",
              "      <td>0.883698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.191248</td>\n",
              "      <td>0.244338</td>\n",
              "      <td>-0.155210</td>\n",
              "      <td>-1.229525</td>\n",
              "      <td>0.014210</td>\n",
              "      <td>-0.697739</td>\n",
              "      <td>1.435658</td>\n",
              "      <td>3.951411</td>\n",
              "      <td>1.520707</td>\n",
              "      <td>5.745880</td>\n",
              "      <td>2.007430</td>\n",
              "      <td>-0.768233</td>\n",
              "      <td>-1.521854</td>\n",
              "      <td>7.365336</td>\n",
              "      <td>-0.692139</td>\n",
              "      <td>-0.388518</td>\n",
              "      <td>1.147070</td>\n",
              "      <td>-1.693861</td>\n",
              "      <td>-0.999421</td>\n",
              "      <td>-0.789475</td>\n",
              "      <td>-1.236924</td>\n",
              "      <td>-1.569647</td>\n",
              "      <td>-1.205133</td>\n",
              "      <td>0.652466</td>\n",
              "      <td>-0.808563</td>\n",
              "      <td>1.630571</td>\n",
              "      <td>-0.364799</td>\n",
              "      <td>0.684779</td>\n",
              "      <td>-2.538839</td>\n",
              "      <td>-0.813365</td>\n",
              "      <td>-0.795446</td>\n",
              "      <td>10.496872</td>\n",
              "      <td>3.774506</td>\n",
              "      <td>-2.294876</td>\n",
              "      <td>6.840396</td>\n",
              "      <td>-3.876951</td>\n",
              "      <td>0.004302</td>\n",
              "      <td>2.426672</td>\n",
              "      <td>0.909436</td>\n",
              "      <td>0.902349</td>\n",
              "      <td>0.580169</td>\n",
              "      <td>0.628177</td>\n",
              "      <td>0.877481</td>\n",
              "      <td>0.978501</td>\n",
              "      <td>0.667469</td>\n",
              "      <td>0.679628</td>\n",
              "      <td>0.588026</td>\n",
              "      <td>0.943516</td>\n",
              "      <td>1.130990</td>\n",
              "      <td>1.025620</td>\n",
              "      <td>1.084985</td>\n",
              "      <td>0.670395</td>\n",
              "      <td>0.892217</td>\n",
              "      <td>0.938884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.058309</td>\n",
              "      <td>0.198829</td>\n",
              "      <td>0.120200</td>\n",
              "      <td>0.220417</td>\n",
              "      <td>0.054295</td>\n",
              "      <td>0.287098</td>\n",
              "      <td>0.505325</td>\n",
              "      <td>1.218140</td>\n",
              "      <td>0.318260</td>\n",
              "      <td>1.586020</td>\n",
              "      <td>0.331255</td>\n",
              "      <td>0.204057</td>\n",
              "      <td>0.701427</td>\n",
              "      <td>1.190853</td>\n",
              "      <td>0.218787</td>\n",
              "      <td>0.102468</td>\n",
              "      <td>0.337828</td>\n",
              "      <td>0.870637</td>\n",
              "      <td>0.879483</td>\n",
              "      <td>0.516007</td>\n",
              "      <td>0.291466</td>\n",
              "      <td>1.028016</td>\n",
              "      <td>0.642749</td>\n",
              "      <td>0.389460</td>\n",
              "      <td>0.801497</td>\n",
              "      <td>0.092480</td>\n",
              "      <td>0.178044</td>\n",
              "      <td>0.698634</td>\n",
              "      <td>1.405891</td>\n",
              "      <td>0.234375</td>\n",
              "      <td>0.084412</td>\n",
              "      <td>0.295581</td>\n",
              "      <td>0.284618</td>\n",
              "      <td>0.321933</td>\n",
              "      <td>0.080644</td>\n",
              "      <td>0.106500</td>\n",
              "      <td>0.025262</td>\n",
              "      <td>0.139112</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066544</td>\n",
              "      <td>0.034851</td>\n",
              "      <td>0.064354</td>\n",
              "      <td>0.091524</td>\n",
              "      <td>0.022133</td>\n",
              "      <td>0.034471</td>\n",
              "      <td>0.029548</td>\n",
              "      <td>0.076547</td>\n",
              "      <td>0.059381</td>\n",
              "      <td>0.061991</td>\n",
              "      <td>0.089998</td>\n",
              "      <td>0.066809</td>\n",
              "      <td>0.078483</td>\n",
              "      <td>0.027378</td>\n",
              "      <td>0.035726</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            bias        f1        f2  ...       f51       f52       f53\n",
              "Fold 1  7.294475  0.395839 -0.096299  ...  0.602390  0.898531  0.950712\n",
              "Fold 2  7.162263  0.237424 -0.082128  ...  0.824143  0.873896  0.970839\n",
              "Fold 3  7.201744  0.255087 -0.032151  ...  0.645763  0.849183  0.977069\n",
              "Fold 4  7.118850 -0.118362 -0.371504  ...  0.645332  0.921416  0.912103\n",
              "Fold 5  7.178907  0.451700 -0.193969  ...  0.634347  0.918059  0.883698\n",
              "mean    7.191248  0.244338 -0.155210  ...  0.670395  0.892217  0.938884\n",
              "std     0.058309  0.198829  0.120200  ...  0.078483  0.027378  0.035726\n",
              "\n",
              "[7 rows x 54 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7GZ43inVmfh4",
        "colab_type": "text"
      },
      "source": [
        "### Stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "ABS5VrvVmfh7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "29cf2ee6-9b63-4d9f-bcf0-4a25383b2649"
      },
      "source": [
        "stats_np = np.array(stats)\n",
        "losses_np = np.expand_dims(np.array(losses), 1)\n",
        "columns = [\"mse_train\"] + [\"mse_val\"] + [\"r2_val\"] + [\"rmse_val\"] + [\"r2/rmse_val\"]\n",
        "index = [f\"Fold {i+1}\" for i, _ in enumerate(stats_np)]  + [\"mean\"] + [\"std\"]\n",
        "all_stats = np.hstack((losses_np, stats_np))\n",
        "all_stats_mean = np.mean(all_stats, axis=0)\n",
        "all_stats_std = np.std(all_stats, axis=0)\n",
        "df = pd.DataFrame(np.vstack((all_stats, all_stats_mean, all_stats_std)),\n",
        "                  columns=columns,\n",
        "                  index=index)\n",
        "\n",
        "display.display(df) "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mse_train</th>\n",
              "      <th>mse_val</th>\n",
              "      <th>r2_val</th>\n",
              "      <th>rmse_val</th>\n",
              "      <th>r2/rmse_val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Fold 1</th>\n",
              "      <td>968.345229</td>\n",
              "      <td>563.167710</td>\n",
              "      <td>0.392779</td>\n",
              "      <td>23.731155</td>\n",
              "      <td>0.016551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fold 2</th>\n",
              "      <td>822.100751</td>\n",
              "      <td>1118.673735</td>\n",
              "      <td>0.293750</td>\n",
              "      <td>33.446580</td>\n",
              "      <td>0.008783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fold 3</th>\n",
              "      <td>897.381531</td>\n",
              "      <td>815.443027</td>\n",
              "      <td>0.309165</td>\n",
              "      <td>28.555963</td>\n",
              "      <td>0.010827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fold 4</th>\n",
              "      <td>831.964562</td>\n",
              "      <td>1083.384766</td>\n",
              "      <td>0.295701</td>\n",
              "      <td>32.914811</td>\n",
              "      <td>0.008984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fold 5</th>\n",
              "      <td>878.874540</td>\n",
              "      <td>881.446683</td>\n",
              "      <td>0.304579</td>\n",
              "      <td>29.689168</td>\n",
              "      <td>0.010259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>879.733323</td>\n",
              "      <td>892.423184</td>\n",
              "      <td>0.319195</td>\n",
              "      <td>29.667535</td>\n",
              "      <td>0.011081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>52.474059</td>\n",
              "      <td>201.052845</td>\n",
              "      <td>0.037225</td>\n",
              "      <td>3.501504</td>\n",
              "      <td>0.002841</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         mse_train      mse_val    r2_val   rmse_val  r2/rmse_val\n",
              "Fold 1  968.345229   563.167710  0.392779  23.731155     0.016551\n",
              "Fold 2  822.100751  1118.673735  0.293750  33.446580     0.008783\n",
              "Fold 3  897.381531   815.443027  0.309165  28.555963     0.010827\n",
              "Fold 4  831.964562  1083.384766  0.295701  32.914811     0.008984\n",
              "Fold 5  878.874540   881.446683  0.304579  29.689168     0.010259\n",
              "mean    879.733323   892.423184  0.319195  29.667535     0.011081\n",
              "std      52.474059   201.052845  0.037225   3.501504     0.002841"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "l5Wo6x-hmfiC",
        "colab_type": "text"
      },
      "source": [
        "MD\n"
      ]
    }
  ]
}