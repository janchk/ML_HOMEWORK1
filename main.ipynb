{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Colab settings\n",
    "# !wget --header=\"Host: archive.ics.uci.edu\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7\" --header=\"Referer: https://archive.ics.uci.edu/ml/machine-learning-databases/00363/\" \"https://archive.ics.uci.edu/ml/machine-learning-databases/00363/Dataset.zip\" -O \"Dataset.zip\" -c\n",
    "# !unzip Dataset.zip\n",
    "# !git clone https://github.com/janchk/ML_HOMEWORK1\n",
    "# from ML_HOMEWORK_1.models import LinearRegressionWithGd\n",
    "# from ML_HOMEWORK_1.common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#import part \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from models import LinearRegressionWithGd\n",
    "from common import *\n",
    "import pandas as pd\n",
    "path = \"Dataset/Training/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# configuration\n",
    "num_folds = 5\n",
    "epochs = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "lrg = LinearRegressionWithGd()\n",
    "lrg.learning_rate = learning_rate\n",
    "\n",
    "df_1, df_2 = folding(path)\n",
    "np.random.shuffle(df_1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def make_table(stats, loss, betas, bias):\n",
    "    columns = [\"Val MSE\", \"Val R2\", \"Val RMSE\", \"Val R2/RMSE\"] + [f\"p{p+1}\" for p in range(len(betas))] + [\"bias\"]\n",
    "    # mean = np.mean([np.sqrt(loss)] + [stats] + [betas] + [bias])\n",
    "    # mean = np.mean(np.sqrt(loss) + stats + betas + bias)\n",
    "    # std = np.std(np.sqrt(loss) + stats + betas + bias)\n",
    "    index = [f\"Fold {i+1}\" for i, _ in enumerate(stats) ]\n",
    "    df = pd.DataFrame(np.array([loss] + [stats] + [betas] + [bias]),\n",
    "                  columns=columns,\n",
    "                  index=index)\n",
    "    display.display(df)   \n",
    "    \n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Loss: 1143.0820: 100%|██████████| 1000/1000 [01:30<00:00, 11.01it/s]\n",
      "Loss: 1093.4475: 100%|██████████| 1000/1000 [01:38<00:00, 10.14it/s]\n",
      "Loss: 1125.7168: 100%|██████████| 1000/1000 [01:33<00:00, 10.70it/s]\n",
      "Loss: 1102.2652: 100%|██████████| 1000/1000 [01:34<00:00, 10.54it/s]\n",
      "Loss: 1011.9705: 100%|██████████| 1000/1000 [01:33<00:00, 10.73it/s]\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "val loss is 1270.1612508211983, R2 is 0.14132154210757586, RMSE is 35.63932169417929, R2/RMSE is 0.003965326369571643\n",
      "val loss is 1167.6259674663008, R2 is 0.1787383922558362, RMSE is 34.17054239350468, R2/RMSE is 0.005230774220599195\n",
      "val loss is 936.4149529333158, R2 is 0.1254947497481238, RMSE is 30.600897910573078, R2/RMSE is 0.0041010152746126915\n",
      "val loss is 921.8500468447003, R2 is 0.1637367854227535, RMSE is 30.361983578888587, R2/RMSE is 0.005392822408895695\n",
      "val loss is 1183.9987252333904, R2 is 0.16816152774190074, RMSE is 34.40928254458948, R2/RMSE is 0.004887097762761766\n",
      "mse_val is 1096.010188659781, r2_val is 0.15549059945523802, rmse is 33.03640562434702, r2/rmse 0.004715407207288198\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "features = []\n",
    "bias = []\n",
    "stats = []\n",
    "losses = [] #loss per fold\n",
    "for i in range(num_folds):\n",
    "    train, test = cv_loo(df_1, num_folds, i)\n",
    "\n",
    "    X_train = normalized(train.T[0:53]).T\n",
    "    X_test = normalized(test.T[0:53]).T\n",
    "\n",
    "    Y_train = train.T[53].T\n",
    "    Y_train = np.expand_dims(Y_train, axis=-1)\n",
    "\n",
    "    Y_test = test.T[53].T\n",
    "    Y_test = np.expand_dims(Y_test, axis=-1)\n",
    "\n",
    "    loss = lrg.train(epochs, X_train, Y_train)\n",
    "    stat = lrg.validate(X_test, Y_test)\n",
    "    losses.append(loss)\n",
    "    stats.append(stat)\n",
    "    features.append(lrg.betas)\n",
    "    bias.append(*lrg.bias)\n",
    "    \n",
    "    # graphs_plot(losses, stats[0], stats[1], stats[2])\n",
    "\n",
    "mean_stats = np.sum(stats, axis=0) / num_folds\n",
    "print(\"mse_val is {}, r2_val is {}, rmse is {}, r2/rmse {}\".format(\n",
    "    mean_stats[0], mean_stats[1], mean_stats[2], mean_stats[3]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Features\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "            bias         f1         f2         f3         f4          f5  \\\nFold 1  4.362976  15.501874   7.906394  40.502210  -9.080475   40.548921   \nFold 2  2.630691  23.555008  11.517066  66.553398 -14.973420   66.989997   \nFold 3  1.405310  29.860006  11.735421  84.746847 -18.058537   88.936926   \nFold 4  0.534440  32.850267   9.138710  94.286941 -18.911005  105.414033   \nFold 5  0.238595  33.147260   6.390099  98.431807 -18.527476  110.424638   \nmean    1.834402  26.982883   9.337538  76.904241 -15.910183   82.462903   \nstd     1.513168   6.697275   2.062779  21.257228   3.687628   25.871678   \n\n               f6          f7          f8          f9  ...       f44  \\\nFold 1  38.269390   69.393365   75.009377   54.028792  ... -0.084542   \nFold 2  61.929655  118.242327  127.810572   90.081750  ... -1.434715   \nFold 3  76.366006  155.695802  170.609669  115.783138  ... -3.164173   \nFold 4  82.776994  180.041109  199.882572  130.221919  ... -3.871227   \nFold 5  84.094901  193.411372  216.533000  137.478019  ... -4.118141   \nmean    68.687389  143.356795  157.969038  105.518724  ... -2.534560   \nstd     17.121864   44.955036   51.260328   30.418796  ...  1.542924   \n\n             f45       f46       f47       f48       f49        f50       f51  \\\nFold 1 -0.892554 -1.764078 -1.814654 -0.058019  2.262402   5.404611  0.080201   \nFold 2 -1.991464 -2.704612 -3.549457 -0.195917  3.314455   8.233231  0.136921   \nFold 3 -2.194861 -3.867728 -5.467131  0.268366  4.821364  11.119688 -1.449363   \nFold 4 -2.392304 -4.609277 -7.389027  0.619703  6.867882  13.440071 -2.618452   \nFold 5 -2.657648 -5.424940 -8.181680  1.359137  7.309542  15.680732 -3.950255   \nmean   -2.025766 -3.674127 -5.280390  0.398654  4.915129  10.775667 -1.560189   \nstd     0.607876  1.308860  2.362463  0.556854  1.957262   3.649364  1.575797   \n\n             f52       f53  \nFold 1 -0.622918 -1.986087  \nFold 2 -2.457493 -2.250175  \nFold 3 -2.988197 -3.012123  \nFold 4 -4.628768 -2.941750  \nFold 5 -5.086451 -3.721195  \nmean   -3.156766 -2.782266  \nstd     1.601765  0.612679  \n\n[7 rows x 54 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bias</th>\n      <th>f1</th>\n      <th>f2</th>\n      <th>f3</th>\n      <th>f4</th>\n      <th>f5</th>\n      <th>f6</th>\n      <th>f7</th>\n      <th>f8</th>\n      <th>f9</th>\n      <th>...</th>\n      <th>f44</th>\n      <th>f45</th>\n      <th>f46</th>\n      <th>f47</th>\n      <th>f48</th>\n      <th>f49</th>\n      <th>f50</th>\n      <th>f51</th>\n      <th>f52</th>\n      <th>f53</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Fold 1</th>\n      <td>4.362976</td>\n      <td>15.501874</td>\n      <td>7.906394</td>\n      <td>40.502210</td>\n      <td>-9.080475</td>\n      <td>40.548921</td>\n      <td>38.269390</td>\n      <td>69.393365</td>\n      <td>75.009377</td>\n      <td>54.028792</td>\n      <td>...</td>\n      <td>-0.084542</td>\n      <td>-0.892554</td>\n      <td>-1.764078</td>\n      <td>-1.814654</td>\n      <td>-0.058019</td>\n      <td>2.262402</td>\n      <td>5.404611</td>\n      <td>0.080201</td>\n      <td>-0.622918</td>\n      <td>-1.986087</td>\n    </tr>\n    <tr>\n      <th>Fold 2</th>\n      <td>2.630691</td>\n      <td>23.555008</td>\n      <td>11.517066</td>\n      <td>66.553398</td>\n      <td>-14.973420</td>\n      <td>66.989997</td>\n      <td>61.929655</td>\n      <td>118.242327</td>\n      <td>127.810572</td>\n      <td>90.081750</td>\n      <td>...</td>\n      <td>-1.434715</td>\n      <td>-1.991464</td>\n      <td>-2.704612</td>\n      <td>-3.549457</td>\n      <td>-0.195917</td>\n      <td>3.314455</td>\n      <td>8.233231</td>\n      <td>0.136921</td>\n      <td>-2.457493</td>\n      <td>-2.250175</td>\n    </tr>\n    <tr>\n      <th>Fold 3</th>\n      <td>1.405310</td>\n      <td>29.860006</td>\n      <td>11.735421</td>\n      <td>84.746847</td>\n      <td>-18.058537</td>\n      <td>88.936926</td>\n      <td>76.366006</td>\n      <td>155.695802</td>\n      <td>170.609669</td>\n      <td>115.783138</td>\n      <td>...</td>\n      <td>-3.164173</td>\n      <td>-2.194861</td>\n      <td>-3.867728</td>\n      <td>-5.467131</td>\n      <td>0.268366</td>\n      <td>4.821364</td>\n      <td>11.119688</td>\n      <td>-1.449363</td>\n      <td>-2.988197</td>\n      <td>-3.012123</td>\n    </tr>\n    <tr>\n      <th>Fold 4</th>\n      <td>0.534440</td>\n      <td>32.850267</td>\n      <td>9.138710</td>\n      <td>94.286941</td>\n      <td>-18.911005</td>\n      <td>105.414033</td>\n      <td>82.776994</td>\n      <td>180.041109</td>\n      <td>199.882572</td>\n      <td>130.221919</td>\n      <td>...</td>\n      <td>-3.871227</td>\n      <td>-2.392304</td>\n      <td>-4.609277</td>\n      <td>-7.389027</td>\n      <td>0.619703</td>\n      <td>6.867882</td>\n      <td>13.440071</td>\n      <td>-2.618452</td>\n      <td>-4.628768</td>\n      <td>-2.941750</td>\n    </tr>\n    <tr>\n      <th>Fold 5</th>\n      <td>0.238595</td>\n      <td>33.147260</td>\n      <td>6.390099</td>\n      <td>98.431807</td>\n      <td>-18.527476</td>\n      <td>110.424638</td>\n      <td>84.094901</td>\n      <td>193.411372</td>\n      <td>216.533000</td>\n      <td>137.478019</td>\n      <td>...</td>\n      <td>-4.118141</td>\n      <td>-2.657648</td>\n      <td>-5.424940</td>\n      <td>-8.181680</td>\n      <td>1.359137</td>\n      <td>7.309542</td>\n      <td>15.680732</td>\n      <td>-3.950255</td>\n      <td>-5.086451</td>\n      <td>-3.721195</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.834402</td>\n      <td>26.982883</td>\n      <td>9.337538</td>\n      <td>76.904241</td>\n      <td>-15.910183</td>\n      <td>82.462903</td>\n      <td>68.687389</td>\n      <td>143.356795</td>\n      <td>157.969038</td>\n      <td>105.518724</td>\n      <td>...</td>\n      <td>-2.534560</td>\n      <td>-2.025766</td>\n      <td>-3.674127</td>\n      <td>-5.280390</td>\n      <td>0.398654</td>\n      <td>4.915129</td>\n      <td>10.775667</td>\n      <td>-1.560189</td>\n      <td>-3.156766</td>\n      <td>-2.782266</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.513168</td>\n      <td>6.697275</td>\n      <td>2.062779</td>\n      <td>21.257228</td>\n      <td>3.687628</td>\n      <td>25.871678</td>\n      <td>17.121864</td>\n      <td>44.955036</td>\n      <td>51.260328</td>\n      <td>30.418796</td>\n      <td>...</td>\n      <td>1.542924</td>\n      <td>0.607876</td>\n      <td>1.308860</td>\n      <td>2.362463</td>\n      <td>0.556854</td>\n      <td>1.957262</td>\n      <td>3.649364</td>\n      <td>1.575797</td>\n      <td>1.601765</td>\n      <td>0.612679</td>\n    </tr>\n  </tbody>\n</table>\n<p>7 rows × 54 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = [\"bias\"] + [f\"f{f+1}\" for f in range(len(features[0]))]\n",
    "index = [f\"Fold {i+1}\" for i, _ in enumerate(features)] + [\"mean\"] + [\"std\"]\n",
    "\n",
    "bias_np = np.expand_dims(np.squeeze(bias), 1)\n",
    "features_np = np.squeeze(features, axis=2)\n",
    "features_np = np.hstack((bias, features_np))\n",
    "features_mean = np.mean(features_np, axis=0)\n",
    "features_std = np.std(features_np, axis=0)\n",
    "df = pd.DataFrame(np.vstack((features_np, features_mean, features_std )),\n",
    "                  columns=columns,\n",
    "                  index=index)\n",
    "\n",
    "display.display(df)    \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stats\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "          mse_train      mse_val    r2_val   rmse_val  r2/rmse_val\nFold 1  1192.737775  1270.161251  0.141322  35.639322     0.003965\nFold 2  1122.014951  1167.625967  0.178738  34.170542     0.005231\nFold 3  1146.093977   936.414953  0.125495  30.600898     0.004101\nFold 4  1114.192491   921.850047  0.163737  30.361984     0.005393\nFold 5  1020.636702  1183.998725  0.168162  34.409283     0.004887",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mse_train</th>\n      <th>mse_val</th>\n      <th>r2_val</th>\n      <th>rmse_val</th>\n      <th>r2/rmse_val</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Fold 1</th>\n      <td>1192.737775</td>\n      <td>1270.161251</td>\n      <td>0.141322</td>\n      <td>35.639322</td>\n      <td>0.003965</td>\n    </tr>\n    <tr>\n      <th>Fold 2</th>\n      <td>1122.014951</td>\n      <td>1167.625967</td>\n      <td>0.178738</td>\n      <td>34.170542</td>\n      <td>0.005231</td>\n    </tr>\n    <tr>\n      <th>Fold 3</th>\n      <td>1146.093977</td>\n      <td>936.414953</td>\n      <td>0.125495</td>\n      <td>30.600898</td>\n      <td>0.004101</td>\n    </tr>\n    <tr>\n      <th>Fold 4</th>\n      <td>1114.192491</td>\n      <td>921.850047</td>\n      <td>0.163737</td>\n      <td>30.361984</td>\n      <td>0.005393</td>\n    </tr>\n    <tr>\n      <th>Fold 5</th>\n      <td>1020.636702</td>\n      <td>1183.998725</td>\n      <td>0.168162</td>\n      <td>34.409283</td>\n      <td>0.004887</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats_np = np.array(stats)\n",
    "losses_np = np.expand_dims(np.array(losses), 1)\n",
    "columns = [\"mse_train\"] + [\"mse_val\"] + [\"r2_val\"] + [\"rmse_val\"] + [\"r2/rmse_val\"]\n",
    "index = [f\"Fold {i+1}\" for i, _ in enumerate(stats_np)] # + [\"mean\"] + [\"std\"]\n",
    "all_stats = np.hstack((losses_np, stats_np))\n",
    "df = pd.DataFrame(all_stats,\n",
    "                  columns=columns,\n",
    "                  index=index)\n",
    "\n",
    "display.display(df) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[4.3629756  2.6306914  1.40531004 0.53443952 0.23859465]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(np.squeeze(bias))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "MD\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}