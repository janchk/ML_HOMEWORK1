{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Colab settings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#import part \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from models import LinearRegressionWithGd\n",
    "from common import *\n",
    "import pandas as pd\n",
    "path = \"Dataset/Training/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# configuration\n",
    "num_folds = 5\n",
    "epochs = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "lrg = LinearRegressionWithGd()\n",
    "lrg.learning_rate = learning_rate\n",
    "\n",
    "df_1, df_2 = folding(path)\n",
    "np.random.shuffle(df_1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def make_table(stats, loss, betas, bias):\n",
    "    columns = [\"Val MSE\", \"Val R2\", \"Val RMSE\", \"Val R2/RMSE\"] + [f\"p{p+1}\" for p in range(len(betas))] + [\"bias\"]\n",
    "    # mean = np.mean([np.sqrt(loss)] + [stats] + [betas] + [bias])\n",
    "    mean = np.mean(np.sqrt(loss) + stats + betas + bias)\n",
    "    std = np.std(np.sqrt(loss) + stats + betas + bias)\n",
    "    index = [f\"Fold {i+1}\" for i, _ in enumerate(stats) ] + [\"Mean\"] + [\"Std\"]\n",
    "    df = pd.DataFrame(np.array([np.sqrt(loss)] + [stats] + [mean] + [std]),\n",
    "                  columns=columns,\n",
    "                  index=index)\n",
    "    display.display(df)   \n",
    "    \n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Loss: 1136.5110: 100%|██████████| 1000/1000 [03:05<00:00,  5.39it/s]\n",
      "Loss: 1032.1506: 100%|██████████| 1000/1000 [02:41<00:00,  6.18it/s]\n",
      "Loss: 1051.4000: 100%|██████████| 1000/1000 [02:44<00:00,  6.08it/s]\n",
      "Loss: 1026.7977: 100%|██████████| 1000/1000 [02:41<00:00,  6.20it/s]\n",
      "Loss: 983.0983: 100%|██████████| 1000/1000 [02:43<00:00,  6.13it/s]\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "val loss is 979.8665163265865, R2 is 0.10219568684502023, RMSE is 31.30281962262484, R2/RMSE is 0.0032647438178749857\n",
      "val loss is 1153.9476014386198, R2 is 0.13838058786894736, RMSE is 33.96980425964536, R2/RMSE is 0.004073635126397753\n",
      "val loss is 928.6936218318536, R2 is 0.16767266997670327, RMSE is 30.474474922988477, R2/RMSE is 0.005502069203831271\n",
      "val loss is 913.1398617294907, R2 is 0.18388740204818432, RMSE is 30.21820414467893, R2/RMSE is 0.006085318676376893\n",
      "val loss is 1005.8675655099954, R2 is 0.17674139827668833, RMSE is 31.71541526623915, R2/RMSE is 0.005572728491587129\n",
      "mse_val is 996.3030333673092, r2_val is 0.1537755490031087, rmse is 31.536143643235352, r2/rmse 0.004899699063213607\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "features = []\n",
    "bias = []\n",
    "stats = []\n",
    "losses = []\n",
    "for i in range(num_folds):\n",
    "    train, test = cv_loo(df_1, num_folds, i)\n",
    "\n",
    "    X_train = normalized(train.T[0:53]).T\n",
    "    X_test = normalized(test.T[0:53]).T\n",
    "\n",
    "    Y_train = train.T[53].T\n",
    "    Y_train = np.expand_dims(Y_train, axis=-1)\n",
    "\n",
    "    Y_test = test.T[53].T\n",
    "    Y_test = np.expand_dims(Y_test, axis=-1)\n",
    "\n",
    "    loss = lrg.train(epochs, X_train, Y_train)\n",
    "    stat = lrg.validate(X_test, Y_test)\n",
    "    losses.append(loss)\n",
    "    stats.append(stat)\n",
    "    features.append(lrg.betas)\n",
    "    bias.append(lrg.bias)\n",
    "    \n",
    "    # graphs_plot(losses, stats[0], stats[1], stats[2])\n",
    "\n",
    "mean_stats = np.sum(stats, axis=0) / num_folds\n",
    "print(\"mse_val is {}, r2_val is {}, rmse is {}, r2/rmse {}\".format(\n",
    "    mean_stats[0], mean_stats[1], mean_stats[2], mean_stats[3]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-60fbeb34d7f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmake_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-a58e88e5865e>\u001b[0m in \u001b[0;36mmake_table\u001b[0;34m(stats, loss, betas, bias)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Val MSE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Val R2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Val RMSE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Val R2/RMSE\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf\"p{p+1}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"bias\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# mean = np.mean([np.sqrt(loss)] + [stats] + [betas] + [bias])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbetas\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbetas\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf\"Fold {i+1}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Mean\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Std\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (5,) (5,4) "
     ],
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (5,) (5,4) ",
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "make_table([list(stat) for stat in stats], losses, features, bias)\n",
    "\n",
    "pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[array([34.14349643, 32.44462416, 32.67248738, 32.23004622, 31.49934581]), [979.8665163265865, 0.10219568684502023, 31.30281962262484, 0.0032647438178749857], [1153.9476014386198, 0.13838058786894736, 33.96980425964536, 0.004073635126397753], [928.6936218318536, 0.16767266997670327, 30.474474922988477, 0.005502069203831271], [913.1398617294907, 0.18388740204818432, 30.21820414467893, 0.006085318676376893], [1005.8675655099954, 0.17674139827668833, 31.71541526623915, 0.005572728491587129]]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "stats = [list(stat) for stat in stats] \n",
    "# np.sqrt(losses)\n",
    "# mean = np.mean(np.sqrt(loss) + stats + bias, axis=0)\n",
    "mean = [val for val in [[np.sqrt(losses)] + stats]]\n",
    "# mean = np.mean(np.sqrt(losses) + stats, axis=0)\n",
    "# mean = np.mean( stats + bias, axis=0 )\n",
    "print(mean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[array([5.67543146]), array([4.52294539]), array([3.5810703]), array([2.77649903]), array([2.08669559])]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print([b[0][] for b in bias])\n",
    "# print(np.concatenate((losses, bias), axis=1))\n",
    "# print(np.sqrt(losses).T, bias)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "MD\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}